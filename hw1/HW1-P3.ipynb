{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "\n",
    "# from utils import *\n",
    "# from network import Network\n",
    "# from statistic import Statistic\n",
    "\n",
    "tf.set_random_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mnist-hw1.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 3) (10000, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "data_trn, data_val = data['train'], data['test']\n",
    "print(data_trn.shape, data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(\n",
    "    layer_in,\n",
    "    output_dim,\n",
    "    kernel_shape, # [kernel_height, kernel_width]\n",
    "    mask_type, # None, \"A\" or \"B\",\n",
    "    scope, \n",
    "    strides=[1, 1], # [column_wise_stride, row_wise_stride]\n",
    "    activation_fn=None,\n",
    "    weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    weights_regularizer=None):\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        mask_type = mask_type.lower()\n",
    "        batch_size, height, width, channel = layer_in.get_shape().as_list()\n",
    "        kernel_h, kernel_w = kernel_shape\n",
    "        stride_h, stride_w = strides\n",
    "\n",
    "        assert kernel_h % 2 == 1 and kernel_w % 2 == 1\n",
    "\n",
    "        center_h = kernel_h // 2\n",
    "        center_w = kernel_w // 2\n",
    "\n",
    "        weights = tf.get_variable(\"weights\", [kernel_h, kernel_w, channel, output_dim],\n",
    "                                  tf.float32, weights_initializer, weights_regularizer)\n",
    "\n",
    "        if mask_type is not None:\n",
    "            mask = np.ones((kernel_h, kernel_w, channel, output_dim), dtype=np.float32)\n",
    "\n",
    "            mask[center_h, center_w+1: ,: ,:] = 0.\n",
    "            mask[center_h+1:, :, :, :] = 0.\n",
    "\n",
    "            if mask_type == 'a':\n",
    "                mask[center_h,center_w,:,:] = 0.\n",
    "\n",
    "            weights *= tf.constant(mask, dtype=tf.float32)\n",
    "\n",
    "        layer_out = tf.nn.conv2d(layer_in, weights, [1, stride_h, stride_w, 1], \n",
    "                                 padding='SAME', name='layer_in_at_weights')\n",
    "        bias = tf.get_variable(\"bias\", [output_dim,], tf.float32, tf.zeros_initializer())\n",
    "        layer_out = tf.nn.bias_add(layer_out, bias, name='layer_in_at_weights_plut_bias')\n",
    "\n",
    "        if activation_fn is not None:\n",
    "            layer_out = activation_fn(layer_out, name='layer_out_activated')\n",
    "\n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self, sess, hidden_dim=16, out_hidden_dim=32, recurrent_length=7, out_recurrent_length=2, \n",
    "                 input_shape=[28, 28, 3], learning_rate=1e-3, grad_clip=1):\n",
    "\n",
    "        self.sess = sess\n",
    "        self.input = tf.placeholder(tf.float32, [None] + input_shape, name=\"input\")\n",
    "\n",
    "        # input of main reccurent layers\n",
    "        nn = conv2d(self.input, output_dim=hidden_dim, kernel_shape=[7, 7], mask_type=\"A\", scope=\"conv_in\")\n",
    "        self.hidden_layers = [nn]\n",
    "        for idx in range(recurrent_length):\n",
    "            nn = conv2d(nn, output_dim=3, kernel_shape=[1, 1], mask_type=\"B\", scope=\"conv_hidden\"+str(idx))\n",
    "            self.hidden_layers.append(nn)\n",
    "        \n",
    "        self.output_layers = []\n",
    "        for idx in range(out_recurrent_length):\n",
    "            nn = conv2d(nn, output_dim=out_hidden_dim, kernel_shape=[1, 1], mask_type=\"B\", scope=\"conv_out\"+str(idx))\n",
    "            nn = tf.nn.relu(nn)\n",
    "            self.output_layers.append(nn)\n",
    "\n",
    "        self.logits = conv2d(nn, output_dim=1, kernel_shape=[1, 1], mask_type=\"B\", scope=\"conv_logits\")\n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.logits, \n",
    "                                                                           labels=self.input, name='loss'))\n",
    "\n",
    "\n",
    "        COLOR_DIM = 4\n",
    "        self.logits = conv2d(nn, output_dim=COLOR_DIM, kernel_shape=[1, 1], mask_type=\"B\", scope=\"conv_logits\")\n",
    "        self.l\n",
    "        \n",
    "#       COLOR_DIM = 4\n",
    "\n",
    "#       self.l['conv2d_out_logits'] = conv2d(l_hid, COLOR_DIM, [1, 1], \"B\", scope='conv2d_out_logits')\n",
    "\n",
    "#       self.l['conv2d_out_logits_flat'] = tf.reshape(\n",
    "#           self.l['conv2d_out_logits'], [-1, self.height * self.width, COLOR_DIM])\n",
    "#       self.l['normalized_inputs_flat'] = tf.reshape(\n",
    "#           self.l['normalized_inputs'], [-1, self.height * self.width, COLOR_DIM])\n",
    "\n",
    "#       # FIXED pre-1.0 # pred_pixels = [tf.squeeze(pixel, squeeze_dims=[1])\n",
    "#       pred_pixels = [tf.squeeze(pixel, axis=[1])\n",
    "#           # FIXED pre-1.0 # for pixel in tf.split(1, self.height * self.width, self.l['conv2d_out_logits_flat'])]\n",
    "#           for pixel in tf.split(self.l['conv2d_out_logits_flat'], self.height * self.width, 1)]\n",
    "#       # FIXED pre-1.0 # target_pixels = [tf.squeeze(pixel, squeeze_dims=[1])\n",
    "#       target_pixels = [tf.squeeze(pixel, axis=[1])\n",
    "#           # FIXED pre-1.0 # for pixel in tf.split(1, self.height * self.width, self.l['normalized_inputs_flat'])]\n",
    "#           for pixel in tf.split(self.l['normalized_inputs_flat'], self.height * self.width, 1)]\n",
    "\n",
    "#       softmaxed_pixels = [tf.nn.softmax(pixel) for pixel in pred_pixels]\n",
    "\n",
    "#       losses = [tf.nn.sampled_softmax_loss(\n",
    "#           pred_pixel, tf.zeros_like(pred_pixel), pred_pixel, target_pixel, 1, COLOR_DIM) \\\n",
    "#               for pred_pixel, target_pixel in zip(pred_pixels, target_pixels)]\n",
    "\n",
    "#       self.l['output'] = tf.nn.softmax(self.l['conv2d_out_logits'])\n",
    "\n",
    "#       logger.info(\"Building loss and optims\")\n",
    "#       # FIXED pre-1.0\n",
    "#       # self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#       #     self.l['conv2d_out_logits'], self.l['normalized_inputs'], name='loss'))\n",
    "#       self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#           logits=self.l['conv2d_out_logits'], labels=self.l['normalized_inputs'], name='loss'))\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "        grads_and_vars = optimizer.compute_gradients(self.loss)\n",
    "\n",
    "        new_grads_and_vars = \\\n",
    "            [(tf.clip_by_value(gv[0], -grad_clip, grad_clip), gv[1]) for gv in grads_and_vars]\n",
    "        self.op = optimizer.apply_gradients(new_grads_and_vars)\n",
    "\n",
    "#   def predict(self, images):\n",
    "#     return self.sess.run(self.l['output'], {self.l['inputs']: images})\n",
    "\n",
    "    def step(self, batch, with_update=False):\n",
    "        if with_update:\n",
    "            _, loss = self.sess.run([self.op, self.loss], feed_dict={self.input: batch})\n",
    "        else:\n",
    "            loss = self.sess.run(self.loss, feed_dict={self.input: batch})\n",
    "        return loss\n",
    "\n",
    "#   def generate(self):\n",
    "#     samples = np.zeros((100, self.height, self.width, 1), dtype='float32')\n",
    "\n",
    "#     for i in xrange(self.height):\n",
    "#       for j in xrange(self.width):\n",
    "#         for k in xrange(self.channel):\n",
    "#           next_sample = binarize(self.predict(samples))\n",
    "#           samples[:, i, j, k] = next_sample[:, i, j, k]\n",
    "\n",
    "#           if self.data == 'mnist':\n",
    "#             print \"=\" * (self.width/2), \"(%2d, %2d)\" % (i, j), \"=\" * (self.width/2)\n",
    "#             mprint(next_sample[0,:,:,:])\n",
    "\n",
    "#     return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(images):\n",
    "    return (np.random.uniform(size=images.shape)*3 < images).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_trn, data_val, batch_size=50, num_epochs=1000, log_per_epoch=50):\n",
    "    with tf.Session() as sess:\n",
    "        network = Network(sess)\n",
    "\n",
    "        iterator = trange(num_epochs, ncols=70, initial=0)\n",
    "        loss_trn = []\n",
    "        loss_val = []\n",
    "\n",
    "        for epoch in iterator:\n",
    "            loss_trn_batch = []\n",
    "            for batch in np.array_split(data_trn, np.ceil(len(data_trn)/batch_size)):\n",
    "                loss = network.step(binarize(batch), with_update=True)\n",
    "                loss_trn_batch.append(loss)\n",
    "\n",
    "            if epoch % log_per_epoch == 0:\n",
    "                loss_trn.append(np.mean(loss_trn_batch))\n",
    "                loss_val.append(network.step(data_val, with_update=False))\n",
    "    return loss_trn, loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "logits and labels must have the same shape ((?, 28, 28, 1) vs (?, 28, 28, 3))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m           \u001b[0mnew_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    263\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\" % (self,\n\u001b[0;32m--> 264\u001b[0;31m                                                                     other))\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 3 and 1 are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m       \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?, 28, 28, 3) and (?, 28, 28, 1) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-1e984dff061d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-773f73773d42>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_trn, data_val, batch_size, num_epochs, log_per_epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-a65410ef9b7d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, hidden_dim, out_hidden_dim, recurrent_length, out_recurrent_length, input_shape, learning_rate, grad_clip)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv_logits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.logits, \n\u001b[0;32m---> 23\u001b[0;31m                                                                            labels=self.input, name='loss'))\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m       raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\u001b[0;32m--> 167\u001b[0;31m                        (logits.get_shape(), labels.get_shape()))\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# The logistic loss formula from above is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: logits and labels must have the same shape ((?, 28, 28, 1) vs (?, 28, 28, 3))"
     ]
    }
   ],
   "source": [
    "loss_trn, loss_val = train(data_trn, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        ...,\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2]],\n",
       "\n",
       "       [[3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        ...,\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2]],\n",
       "\n",
       "       [[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [3, 2, 3],\n",
       "        ...,\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        ...,\n",
       "        [3, 2, 3],\n",
       "        [3, 2, 3],\n",
       "        [3, 2, 3]],\n",
       "\n",
       "       [[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        ...,\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 3],\n",
       "        [3, 2, 3]],\n",
       "\n",
       "       [[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        ...,\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 2]]], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
