{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Flow in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "    count = 100000\n",
    "    rand = np.random.RandomState(0)\n",
    "    a = [[-1.5, 2.5]] + rand.randn(count // 3, 2) * 0.2\n",
    "    b = [[1.5, 2.5]] + rand.randn(count // 3, 2) * 0.2\n",
    "    c = np.c_[2 * np.cos(np.linspace(0, np.pi, count // 3)),\n",
    "    -np.sin(np.linspace(0, np.pi, count // 3))]\n",
    "\n",
    "    c += rand.randn(*c.shape) * 0.2\n",
    "    data_x = np.concatenate([a, b, c], axis=0)\n",
    "    data_y = np.array([0] * len(a) + [1] * len(b) + [2] * len(c))\n",
    "    perm = rand.permutation(len(data_x))\n",
    "    return data_x[perm], data_y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = sample_data()\n",
    "data_trn, data_val = data_x[:80000], data_x[80000:]\n",
    "data_trn_y, data_val_y = data_y[:80000], data_y[80000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(layer_in, scope, num_layers, hidden_dim, output_dim, activation=tf.tanh, output_activation=None):\n",
    "    '''\n",
    "    layer_out = (None, k)\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        nn = layer_in\n",
    "        for idx in range(num_layers):\n",
    "            nn = tf.layers.dense(nn, hidden_dim, activation=activation)\n",
    "        layer_out = tf.layers.dense(nn, output_dim, activation=output_activation)\n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_g(layer_in, mask_post, mask_prior, scope, k, num_layers, hidden_dim):\n",
    "    '''\n",
    "    layer_in, mask = (None, 2)\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        prior = layer_in * mask_prior\n",
    "        pi = build_mlp(prior, \"pi\", num_layers, hidden_dim, k, output_activation=tf.nn.softmax)\n",
    "        mu = build_mlp(prior, \"mu\", num_layers, hidden_dim, k)\n",
    "        sigma2 = build_mlp(prior, \"sigma2\", num_layers, hidden_dim, k)\n",
    "        norm_dist = tfp.distributions.Normal(0, 1)\n",
    "        shifted = tf.reduce_sum((layer_in*mask_post - tf.expand_dims(mu, axis=-1))/sigma2, axis=-1)\n",
    "        print(tf.shape(shifted)) # shold be (None, k)\n",
    "        layer_out = tf.reduce_sum(norm_dist.get_prob(shifted) * pi, axis=-1, name=\"layer_out\")\n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log p_{\\theta}(x)=\\log p\\left(f_{\\theta}(x)\\right)+\\log \\left|\\operatorname{det} \\frac{\\partial f_{\\theta}(x)}{\\partial x}\\right|$$\n",
    "$$f_\\theta\\left(\\mathbf{x}_1\\right) := \\int_{-\\infty}^{\\mathbf{x}_1} g_\\theta\\left(\\mathbf{t}\\right) d\\mathbf{t}$$\n",
    "$$f_\\theta\\left(\\mathbf{x}_2|\\mathbf{x}_1\\right) := \\int_{-\\infty}^{\\mathbf{x}_2} g_\\theta\\left(\\mathbf{t}|\\mathbf{x}_1\\right) d\\mathbf{t}$$\n",
    "$$\n",
    "\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}}=\\left[ \\begin{array}{cc}{g_\\theta\\left(\\mathbf{x}_1\\right)} & {0} \\\\ {g_\\theta\\left(\\mathbf{x}_2|\\mathbf{x}_1\\right)^T\\frac{\\partial g_\\theta\\left(\\mathbf{x}_2|\\mathbf{x}_1\\right)}{\\partial \\mathbf{x}_1}} & {g_\\theta\\left(\\mathbf{x}_2|\\mathbf{x}_1\\right)}\\end{array}\\right]\n",
    "$$\n",
    "For uniform base distribution, the first term is 0; the second term is \n",
    "$$\\left|g_\\theta\\left(\\mathbf{x}_1\\right)g_\\theta\\left(\\mathbf{x}_2|\\mathbf{x}_1\\right)\\right|$$\n",
    "To generate samples, \n",
    "$$p_{\\theta}(\\mathbf{x}_1, \\mathbf{x}_2) = g_\\theta\\left(\\mathbf{x}_1\\right)g_\\theta\\left(\\mathbf{x}_2|\\mathbf{x}_1\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixGaussian():\n",
    "    def __init__(self, sess, k, num_layers=4, hidden_dim=8, learning_rate=1e-3):\n",
    "        self.sess = sess\n",
    "        self.input = tf.placeholder(shape=[None, 2], name=\"input\", dtype=tf.float32)\n",
    "        self.k = k\n",
    "        \n",
    "        mask_post_1 = tf.constant([1.0, .0], dtype=tf.float32, name=\"mask_post_1\")\n",
    "        mask_prior_1 = tf.constant([.0, .0], dtype=tf.float32, name=\"mask_prior_1\")\n",
    "        self.g_1 = build_g(self.input, mask_post_1, mask_prior_2, \"g_1\", k, num_layers, hidden_dim)\n",
    "        mask_post_2 = tf.constant([.0, 1.0], dtype=tf.float32, name=\"mask_post_2\")\n",
    "        mask_prior_2 = tf.constant([1.0, .0], dtype=tf.float32, name=\"mask_prior_2\")\n",
    "        self.g_2 = build_g(mask_post_2, mask_prior_2, \"g_2\", k, num_layers, hidden_dim)\n",
    "        \n",
    "        self.density_model = tf.abs(self.g_1 * self.g_2)\n",
    "        self.loss = tf.reduce_mean(-tf.log(self.density_model), axis=0)\n",
    "        print(tf.shape(self.loss)) # should be a scalar\n",
    "        self.op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "    \n",
    "    def step(self, batch, with_update=False):\n",
    "        if with_update:\n",
    "            loss, _ = self.sess.run([self.loss, self.op], feed_dict={self.input: batch})\n",
    "        else:\n",
    "            loss = self.sess.run(self.loss, feed_dict={self.input: batch})\n",
    "        return loss\n",
    "    \n",
    "    def evaluate(self, samples):\n",
    "        return self.sess.run(self.density_model, feed_dict={self.input: samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density_model(network, step=0.1):\n",
    "    x, y = np.arange(-4, 4, step), np.arange(-4, 4, step)\n",
    "    xv, yv = meshgrid(x, y)\n",
    "    xv, yv = np.array(xv).flatten(), np.array(yv).flatten()\n",
    "    z = network.evaluate(list(zip(xv, yv)))\n",
    "    plt.pcolormesh(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, data_trn, data_val, k=6, batch_size=256, num_epochs=5, log_per_epoch=1):\n",
    "    network = MixGaussian(sess)\n",
    "    init_op = tf.initializers.global_variables()\n",
    "    sess.run(init_op)\n",
    "\n",
    "    loss_trn = []\n",
    "    loss_val = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('starting epoch', epoch)\n",
    "        loss_trn_batch = []\n",
    "        for batch in np.array_split(data_trn, np.ceil(len(data_trn)/batch_size)):\n",
    "            loss = network.step(batch, with_update=True)\n",
    "            loss_trn_batch.append(loss)\n",
    "\n",
    "        if epoch % log_per_epoch == 0:\n",
    "            loss_trn.append(np.mean(loss_trn_batch))\n",
    "            loss_val.append(network.step(data_val, with_update=False))\n",
    "            print(loss_trn[-1], loss_val[-1])\n",
    "    return loss_trn, loss_val, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_trn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-59666dd00a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_trn' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "loss_trn, loss_val, network = train(sess, data_trn, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-80051a7e9a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_density_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "plot_density_model(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
