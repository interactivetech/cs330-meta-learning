{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hw2_q2.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 32, 3) (6838, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "data_trn, data_val = data['train'], data['test']\n",
    "print(data_trn.shape, data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(tensor):\n",
    "    return tf.check_numerics(tensor, tensor.name)\n",
    "\n",
    "def pprint(tensor, reshape=False):\n",
    "#     tensor_to_print = tf.reshape(tensor, [-1, np.prod(tensor.get_shape()[1:])]) if reshape else tensor\n",
    "    mean, var = tf.nn.moments(tensor, axes=-1)\n",
    "    \n",
    "    with tf.control_dependencies([tf.print(tensor.name, \" has shape \", \n",
    "                                           tf.shape(tensor), \"\\n\", \n",
    "                                           \"mean: \", mean, \n",
    "                                           \"var: \", var, \"\\n\", \n",
    "#                                            tensor_to_print, \n",
    "                                           output_stream=sys.stdout)]):\n",
    "        return tf.check_numerics(tensor, tensor.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(layer_in, num_channels, output_dim, num_filters=6, num_blocks=2, scope=\"resnet\"):\n",
    "    \n",
    "#     TODO: BatchNorm & WeightNormalization\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        h = conv2d(layer_in, scope=\"conv2d\", kernel=(3, 3), stride=(1, 1), \n",
    "                   in_channels=num_channels, out_channels=num_filters)\n",
    "        \n",
    "        for idx in range(num_blocks):\n",
    "            _h = conv2d(h, scope=\"conv2d_\"+str(idx)+\"_0\", kernel=(1, 1), stride=(1, 1), \n",
    "                        in_channels=num_filters, out_channels=num_filters)\n",
    "            _h = tf.nn.relu(_h)\n",
    "            _h = conv2d(_h, scope=\"conv2d_\"+str(idx)+\"_1\", kernel=(3, 3), stride=(1, 1), \n",
    "                        in_channels=num_filters, out_channels=num_filters)\n",
    "            _h = tf.nn.relu(_h)\n",
    "            _h = conv2d(_h, scope=\"conv2d_\"+str(idx)+\"_2\", kernel=(1,1), stride=(1, 1), \n",
    "                        in_channels=num_filters, out_channels=num_filters)\n",
    "            h = h + _h\n",
    "        h = tf.nn.relu(h)\n",
    "        layer_out = conv2d(h, scope=\"resnet_layer_out\", kernel=(3, 3), stride=(1, 1), \n",
    "                           in_channels=num_filters, out_channels=output_dim)\n",
    "        layer_out = tf.nn.tanh(layer_out)\n",
    "\n",
    "    return layer_out\n",
    "        \n",
    "def conv2d(layer_in, scope, kernel, stride, in_channels, out_channels):\n",
    "    with tf.variable_scope(scope):\n",
    "        kernel_h, kernel_w = kernel\n",
    "        stride_h, stride_w = stride\n",
    "        weights = tf.get_variable(\"weights\", [kernel_h, kernel_w, in_channels, out_channels], tf.float32)\n",
    "        layer_out = tf.nn.conv2d(input=layer_in, filter=weights, strides=[1, stride_h, stride_w, 1], \n",
    "                                 padding='SAME', name='conv2d_layer_out')\n",
    "\n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y=b \\odot x+(1-b) \\odot(x \\odot \\exp (s(b \\odot x))+t(b \\odot x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def x2y(self, x, sum_log_jacobian):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def y2x(self, y):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingLayer(Layer):\n",
    "    def __init__(self, scope, mask_type):\n",
    "        self.scope = scope\n",
    "        self.mask_type = mask_type\n",
    "        \n",
    "    def _get_mask(self, shape):\n",
    "        if self.mask_type.startswith(\"checkerboard\"):\n",
    "            if self.mask_type == \"checkerboard0\":\n",
    "                mask = tf.constant([[0.0, 1.0], [1.0, 0.0]], dtype=tf.float32)\n",
    "            elif self.mask_type == \"checkerboard1\": \n",
    "                mask = tf.constant([[1.0, 0.0], [0.0, 1.0]], dtype=tf.float32)\n",
    "            mask = tf.reshape(mask, [1, 2, 2, 1], name=\"mask_\" + self.mask_type)\n",
    "            shape = [shape[0], shape[1]//2, shape[2]//2, shape[3]]\n",
    "            mask = tf.tile(mask, shape)\n",
    "        elif self.mask_type.startswith(\"channel\"):\n",
    "            shape = [shape[0], shape[1], shape[2], shape[3]//2]\n",
    "            ones = tf.ones(shape)\n",
    "            zeros = tf.zeros(shape)\n",
    "            if self.mask_type == \"channel0\":\n",
    "                mask = tf.concat([ones, zeros], axis=-1, name=\"mask_\" + self.mask_type)\n",
    "            elif self.mask_type == \"channel1\": \n",
    "                mask = tf.concat([zeros, ones], axis=-1, name=\"mask_\" + self.mask_type)\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def _build_log_s_t(self, masked_in, scope=\"_build_log_s_t\"):\n",
    "        num_channels = masked_in.get_shape()[-1]\n",
    "        with tf.variable_scope(scope):\n",
    "            resnet_out = resnet(masked_in, num_channels, num_channels * 2)\n",
    "            log_s, t = tf.split(resnet_out, 2, axis=-1)\n",
    "\n",
    "        return log_s, t\n",
    "    \n",
    "    def x2y(self, x, sum_log_jacobian):\n",
    "        '''\n",
    "        sum_log_jacobian = (None,)\n",
    "        '''\n",
    "        with tf.variable_scope(self.scope):\n",
    "            mask = self._get_mask(tf.shape(x))\n",
    "            masked_x = mask * x\n",
    "            log_s, t = self._build_log_s_t(masked_x)\n",
    "            \n",
    "            y = masked_x + (1 - mask) * (x * tf.exp(log_s) + t)\n",
    "            sum_log_jacobian += tf.reduce_sum(log_s, axis=[1, 2, 3])\n",
    "        \n",
    "        return y, sum_log_jacobian\n",
    "        \n",
    "    def y2x(self, y):\n",
    "        with tf.variable_scope(self.scope, reuse=True):\n",
    "            mask = self._get_mask(tf.shape(y))\n",
    "            masked_y = mask * y\n",
    "            log_s, t = self._build_log_s_t(masked_y)\n",
    "            x = masked_y + ((1 - mask) * y - t) * tf.exp(-log_s)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezingLayer(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def x2y(self, x, sum_log_det_jacobians):\n",
    "        y = tf.space_to_depth(x, 2)\n",
    "        return y, sum_log_det_jacobians\n",
    "    \n",
    "    def y2x(self, y):\n",
    "        x = tf.depth_to_space(y, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNVP():\n",
    "    def __init__(self, sess, input_shape=(32, 32, 3), learning_rate=1e-5):\n",
    "        self.sess = sess\n",
    "        self.x = tf.placeholder(tf.float32, (None,) + input_shape, name=\"x\")\n",
    "        self._build_layers()\n",
    "#         self._build_toy_layers()\n",
    "        self._build_loss()\n",
    "        self._build_op(learning_rate)\n",
    "        \n",
    "        self.z_sample = tf.placeholder(tf.float32, (None,) + self.output_shape, name=\"z_sample\")\n",
    "        self._build_sample()\n",
    "\n",
    "    def _build_layers(self):\n",
    "        self.layers = []\n",
    "        self.layers.extend([CouplingLayer(\n",
    "            \"0_checkerboard_idx_\"+str(idx), \"checkerboard\" + str(idx % 2)\n",
    "        ) for idx in range(4)])\n",
    "        self.layers.append(SqueezingLayer())\n",
    "        self.layers.extend([CouplingLayer(\n",
    "            \"1_channel_idx_\" + str(idx), \"channel\" + str(idx % 2)\n",
    "        ) for idx in range(3)])\n",
    "        self.layers.extend([CouplingLayer(\n",
    "            \"2_checkerboard_idx_\"+str(idx), \"checkerboard\" + str(idx % 2)\n",
    "        ) for idx in range(3)])\n",
    "        self.layers.append(SqueezingLayer())\n",
    "        self.layers.extend([CouplingLayer(\n",
    "            \"3_channel_idx_\" + str(idx), \"channel\" + str(idx % 2)\n",
    "        ) for idx in range(3)])\n",
    "        self.layers.extend([CouplingLayer(\n",
    "            \"4_checkerboard_idx_\"+str(idx), \"checkerboard\" + str(idx % 2)\n",
    "        ) for idx in range(3)])\n",
    "        \n",
    "    def _build_toy_layers(self):\n",
    "        self.layers = [CouplingLayer(\n",
    "            \"0_checkerboard_idx_\"+str(idx), \"checkerboard\" + str(idx % 2)\n",
    "        ) for idx in range(4)]\n",
    "        \n",
    "    def _preprocess(x, alpha=0.05):\n",
    "        return x, 0\n",
    "        x = x + np.random.uniform(size=batch.shape)\n",
    "        x = alpha + (1-alpha) * x/4\n",
    "        log_jacobian = np.prod(input_shape[1:]) * np.log((1-alpha)/4)\n",
    "        return x, log_jacobian\n",
    "        \n",
    "    def _build_loss(self):\n",
    "        print(\"building loss...\")\n",
    "        y, sum_log_jacobian = self.x, 0\n",
    "        for layer in self.layers:\n",
    "            y, sum_log_jacobian = layer.x2y(y, sum_log_jacobian)\n",
    "            sum_log_jacobian = pprint(sum_log_jacobian, True)\n",
    "\n",
    "        self.output_shape = tuple(y.get_shape()[1:])\n",
    "        base_dim = np.prod(self.output_shape)\n",
    "        base_dist = tfp.distributions.MultivariateNormalDiag(\n",
    "            loc=[0.0] * base_dim, \n",
    "            scale_diag=[1.0] * base_dim)\n",
    "        log_pz = base_dist.log_prob(tf.reshape(y, [-1, base_dim]))\n",
    "        log_pz = debug(log_pz)\n",
    "        self.loss = - tf.reduce_mean(log_pz + sum_log_jacobian, axis=0)\n",
    "        \n",
    "        # negative log likelihood to bits per dim\n",
    "        self.loss = self.loss / int(base_dim) + tf.log(4.0)\n",
    "        self.loss = debug(self.loss)\n",
    "    \n",
    "    def _build_op(self, learning_rate, grad_clip=1):\n",
    "        if grad_clip > 0:\n",
    "            op = tf.train.AdamOptimizer(learning_rate)\n",
    "            grads_and_vars = op.compute_gradients(self.loss)\n",
    "            new_grads_and_vars = [\n",
    "                (tf.clip_by_value(gv[0], -grad_clip, grad_clip), gv[1]) \n",
    "                for gv in grads_and_vars]\n",
    "            self.op = op.apply_gradients(new_grads_and_vars)\n",
    "        else:\n",
    "            self.op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "        \n",
    "    def _build_sample(self):\n",
    "        print(\"building samples...\")\n",
    "        y = self.z_sample\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.y2x(y)\n",
    "        self.x_sample = y\n",
    "    \n",
    "    def step(self, batch, with_update=False):\n",
    "        if with_update:\n",
    "            loss, _ = self.sess.run([self.loss, self.op], feed_dict={self.x: batch})\n",
    "        else:\n",
    "            loss = self.sess.run(self.loss, feed_dict={self.x: batch})\n",
    "        return loss\n",
    "    \n",
    "    def sample(self, batch):\n",
    "        return self.sess.run(self.x_sample, feed_dict={self.z_sample: batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, data_trn, data_val, batch_size=128, num_epochs=10, \n",
    "          log_per_epoch=1, print_per_epoch=1):\n",
    "    print(\"building model...\")\n",
    "    model = RealNVP(sess)\n",
    "    init_op = tf.initializers.global_variables()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    loss_trn = []\n",
    "    loss_val = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch {} starts...\".format(epoch))\n",
    "        loss_trn_batch = []\n",
    "        for batch in np.array_split(data_trn, np.ceil(len(data_trn)/batch_size)):\n",
    "            loss = model.step(batch, with_update=True)\n",
    "            loss_trn_batch.append(loss)\n",
    "\n",
    "        if epoch % log_per_epoch == 0:\n",
    "            loss_trn.append(np.mean(loss_trn_batch))\n",
    "            loss_val.append(model.step(data_val, with_update=False))\n",
    "\n",
    "        if epoch % print_per_epoch == 0:\n",
    "            print(\"at epoch\", epoch, loss_trn[-1], loss_val[-1])\n",
    "            \n",
    "    return loss_trn, loss_val, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "building loss...\n",
      "building samples...\n",
      "epoch 0 starts...\n",
      "at epoch 0 223.0865 199.23868\n",
      "epoch 1 starts...\n",
      "at epoch 1 179.36868 172.15715\n",
      "epoch 2 starts...\n",
      "at epoch 2 145.15915 146.87665\n",
      "epoch 3 starts...\n",
      "at epoch 3 118.026375 124.6189\n",
      "epoch 4 starts...\n",
      "at epoch 4 95.92245 104.522736\n",
      "epoch 5 starts...\n",
      "at epoch 5 77.31355 87.00415\n",
      "epoch 6 starts...\n",
      "at epoch 6 62.29827 72.90486\n",
      "epoch 7 starts...\n",
      "at epoch 7 50.565323 60.474285\n",
      "epoch 8 starts...\n",
      "at epoch 8 41.467194 49.51318\n",
      "epoch 9 starts...\n",
      "at epoch 9 34.328903 39.495983\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "loss_trn, loss_val, model = train(sess, data_trn[:1024], data_val[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(sess, model, num_samples):\n",
    "    z = np.random.normal(0.0, 1.0, (num_samples,) + model.output_shape)\n",
    "    samples = model.sample(z)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(sess, model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55935580000.0 -23841714000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c3d93e940>"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(max(samples[0].flatten()), min(samples[0].flatten()))\n",
    "plt.imshow(samples[0]/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
